# Laboratorio 1 - Arquitecturas del Software (ARSW)
## Andr√©s Jacobo Sep√∫lveda S√°nchez

**Descripci√≥n**

Este ejercicio contiene una introducci√≥n a la programaci√≥n con hilos en Java, adem√°s de la aplicaci√≥n a un caso concreto.

### Parte 1 Introducci√≥n a Hilos en Java

**1.** De acuerdo con lo revisado en las lecturas, complete las clases CountThread, para que las mismas definan el ciclo de vida de un hilo que imprima por pantalla los n√∫meros entre A y B.

![CountThread](images/CountThread.png)

**2.1** Complete el m√©todo main de la clase CountMainThreads para que cree 3 hilos de tipo CountThread, asign√°ndole al primero el intervalo [0..99], al segundo [99..199], y al tercero [200..299].

![CountThreadMain](images/CountThreadMain.png)

**2.2** Inicie los tres hilos con 'start()'

![CountThreadMain2](images/CountThreadMain2.png)

**2.3** Ejecute y revise la salida por pantalla.

![2-3](images/2-3.png)

**2.4**  Cambie el incio con 'start()' por 'run()'. C√≥mo cambia la salida?, por qu√©?.

Cuando cambiamos start() por run() la salida en este caso se muestra en orden. Esto se debe a que con run() no se ejecutan todos los hilos de forma paralela si no que se ejecuta de manera bloqueante, es decir, uno detras del otro lo que implica que hasta que el primer hilo no acabe el segundo no se va a ejecutar. 

![2-4](images/2-4.png)

### Parte 2 Ejercicio Black List Search
Para un software de vigilancia autom√°tica de seguridad inform√°tica se est√° desarrollando un componente encargado de validar las direcciones IP en varios miles de listas negras (de host maliciosos) conocidas, y reportar aquellas que existan en al menos cinco de dichas listas.

Dicho componente est√° dise√±ado de acuerdo con el siguiente diagrama, donde:

- HostBlackListsDataSourceFacade es una clase que ofrece una 'fachada' para realizar consultas en cualquiera de las N listas negras registradas (m√©todo 'isInBlacklistServer'), y que permite tambi√©n hacer un reporte a una base de datos local de cuando una direcci√≥n IP se considera peligrosa. Esta clase NO ES MODIFICABLE, pero se sabe que es 'Thread-Safe'.

  ![BlackList1](images/HostBlackList.png)

- HostBlackListsValidator es una clase que ofrece el m√©todo 'checkHost', el cual, a trav√©s de la clase 'HostBlackListDataSourceFacade', valida en cada una de las listas negras un host determinado. En dicho m√©todo est√° considerada la pol√≠tica de que al encontrarse un HOST en al menos cinco listas negras, el mismo ser√° registrado como 'no confiable', o como 'confiable' en caso contrario. Adicionalmente, retornar√° la lista de los n√∫meros de las 'listas negras' en donde se encontr√≥ registrado el HOST.

  ![BlackList2](images/HostBlackListValidator.png)

Al usarse el m√≥dulo, la evidencia de que se hizo el registro como 'confiable' o 'no confiable' se d√° por lo mensajes de LOGs:

INFO: HOST 205.24.34.55 Reported as trustworthy

INFO: HOST 205.24.34.55 Reported as NOT trustworthy

![NotTrustWorthy](images/NotTrustWorthy.png)

Al programa de prueba provisto (Main), le toma s√≥lo algunos segundos an√°lizar y reportar la direcci√≥n provista (200.24.34.55), ya que la misma est√° registrada m√°s de cinco veces en los primeros servidores, por lo que no requiere recorrerlos todos. Sin embargo, hacer la b√∫squeda en casos donde NO hay reportes, o donde los mismos est√°n dispersos en las miles de listas negras, toma bastante tiempo.

√âste, como cualquier m√©todo de b√∫squeda, puede verse como un problema vergonzosamente paralelo, ya que no existen dependencias entre una partici√≥n del problema y otra.

Para 'refactorizar' este c√≥digo, y hacer que explote la capacidad multi-n√∫cleo de la CPU del equipo, realice lo siguiente:

1. Cree una clase de tipo Thread que represente el ciclo de vida de un hilo que haga la b√∫squeda de un segmento del conjunto de servidores disponibles. Agregue a dicha clase un m√©todo que permita 'preguntarle' a las instancias del mismo (los hilos) cuantas ocurrencias de servidores maliciosos ha encontrado o encontr√≥.
   ![classThread](images/claseThread.png)
   ![classThread2](images/claseThread2.png)
2. Agregue al m√©todo 'checkHost' un par√°metro entero N, correspondiente al n√∫mero de hilos entre los que se va a realizar la b√∫squeda (recuerde tener en cuenta si N es par o impar!). Modifique el c√≥digo de este m√©todo para que divida el espacio de b√∫squeda entre las N partes indicadas, y paralelice la b√∫squeda a trav√©s de N hilos. Haga que dicha funci√≥n espere hasta que los N hilos terminen de resolver su respectivo sub-problema, agregue las ocurrencias encontradas por cada hilo a la lista que retorna el m√©todo, y entonces calcule (sumando el total de ocurrencuas encontradas por cada hilo) si el n√∫mero de ocurrencias es mayor o igual a BLACK_LIST_ALARM_COUNT. Si se da este caso, al final se DEBE reportar el host como confiable o no confiable, y mostrar el listado con los n√∫meros de las listas negras respectivas. Para lograr este comportamiento de 'espera' revise el m√©todo join del API de concurrencia de Java. Tenga tambi√©n en cuenta:
   ![CheckHost](images/checkHost.png)
    - Dentro del m√©todo checkHost Se debe mantener el LOG que informa, antes de retornar el resultado, el n√∫mero de listas negras revisadas VS. el n√∫mero de listas negras total (l√≠nea 60). Se debe garantizar que dicha informaci√≥n sea ver√≠dica bajo el nuevo esquema de          procesamiento en paralelo planteado.
      ![checkHost2](images/checkHost2.png)
    - Se sabe que el HOST 202.24.34.55 est√° reportado en listas negras de una forma m√°s dispersa, y que el host 212.24.24.55 NO est√° en ninguna lista negra.
      ![BlackListHost](images/blackListHost.png)

La estrategia de paralelismo antes implementada es ineficiente en ciertos casos, pues la b√∫squeda se sigue realizando a√∫n cuando los N hilos (en su conjunto) ya hayan encontrado el n√∫mero m√≠nimo de ocurrencias requeridas para reportar al servidor como malicioso. C√≥mo se podr√≠a modificar la implementaci√≥n para minimizar el n√∫mero de consultas en estos casos?, qu√© elemento nuevo traer√≠a esto al problema?

Tras revisar el problema y comparar soluciones t√≠picas en programaci√≥n concurrente, propongo dos medidas combinadas que reducen significativamente las comprobaciones redundantes:
1. Se√±al de cancelaci√≥n cooperativa (stop)

    - Introducir un AtomicBoolean stop compartido.

    - Cada hilo antes de iniciar una nueva verificaci√≥n comprueba stop.get(). Si es true, el hilo sale.

    - Cuando cualquier hilo incrementa el contador global de ocurrencias y detecta que se alcanza el umbral (>= BLACK_LIST_ALARM_COUNT), hace stop.set(true).

    As√≠ se impide que se inicien nuevas comprobaciones despu√©s de alcanzado el umbral.

2. Asignaci√≥n de trabajo din√°mica mediante un √≠ndice global (nextIndex)

    - En vez de particionar de forma est√°tica, usar un AtomicInteger nextIndex que act√∫e como ‚Äúcola ligera‚Äù: cada hilo hace i = nextIndex.getAndIncrement() para obtener la siguiente lista a chequear.

    - Mientras i < totalServers y !stop.get(), el hilo procesa i.

    De esta manera se evita que un hilo est√© atascado con un sub-rango grande mientras otros ya terminaron; permite que el trabajo se consumA hasta que alguien active stop.

Al introducir estos cambios incorporamos cancelaci√≥n cooperativa y planificaci√≥n din√°mica donde conseguimos:

- Necesidad de visibilidad y atomicidad: hay que usar variables at√≥micas (AtomicBoolean, AtomicInteger) o volatile para asegurar que todos los hilos vean la se√±al stop sin retrasos.

- Mayor coordinaci√≥n entre hilos: ahora los hilos colaboran (cooperan) para dejar de trabajar en cuanto el conjunto ha alcanzado la meta. Esto a√±ade una dependencia ligera (la se√±al stop) que antes no exist√≠a.

- Cambio de patr√≥n de particionado: pasamos de partici√≥n est√°tica a asignaci√≥n din√°mica, lo que altera c√≥mo se razona sobre balance de carga y rendimiento.

- Posible falta de determinismo en orden de comprobaciones: al ser din√°mica, las listas se chequean en orden ‚Äúrace‚Äù (qui√©n hace getAndIncrement primero), por lo que la secuencia de comprobaciones puede variar entre ejecuciones; esto puede afectar pruebas que dependen del orden.

- Manejo de llamadas bloqueantes: si isInBlacklistServer puede bloquear largo tiempo, la cancelaci√≥n cooperativa s√≥lo evita nuevas comprobaciones; las llamadas en curso seguir√°n hasta terminar a menos que se implementen interrupciones/timeouts en esa funci√≥n.

- Coste extra de sincronizaci√≥n at√≥mica: las operaciones at√≥micas tienen un coste (peque√±o), pero mucho menor que el ahorro al evitar consultas redundantes en escenarios realistas.

### Parte III - Evaluaci√≥n de Desempe√±o

A partir de lo anterior, implemente la siguiente secuencia de experimentos para realizar las validaci√≥n de direcciones IP dispersas (por ejemplo 202.24.34.55), tomando los tiempos de ejecuci√≥n de los mismos (aseg√∫rese de hacerlos en la misma m√°quina).
Al iniciar el programa ejecute el monitor jVisualVM, y a medida que corran las pruebas, revise y anote el consumo de CPU y de memoria en cada caso.

1. Un solo hilo.
   ![unHilo](images/hilo1.png)

2. Tantos hilos como n√∫cleos de procesamiento (haga que el programa determine esto haciendo uso del API Runtime).
   ![coreHilo](images/hilocore.png)
3. Tantos hilos como el doble de n√∫cleos de procesamiento.
   ![coreHilo2](images/hilocore2.png)
4. 50 hilos.
   ![Hilo50](images/hilo50.png)
5. 100 hilos.
   ![Hilo100](images/hilo100.png)

Con lo anterior, y con los tiempos de ejecuci√≥n dados, haga una gr√°fica de tiempo de soluci√≥n vs. n√∫mero de hilos. Analice y plantee hip√≥tesis con su compa√±ero para las siguientes preguntas (puede tener en cuenta lo reportado por jVisualVM):

![grafica](images/grafica.png)

### Parte IV - Ejercicio Black List Search

1. Seg√∫n la ley de Amdahls:

   ![amdahls](img/ahmdahls.png)
   
   donde S(n) es el mejoramiento te√≥rico del desempe√±o, P la fracci√≥n paralelizable del algoritmo, y n el n√∫mero de hilos, a mayor n, mayor deber√≠a ser dicha mejora. Por qu√© el mejor desempe√±o no se logra con los 500 hilos?, c√≥mo se compara este desempe√±o cuando se usan 200?.

   Aunque Amdahl sugiere que al subir ùëõ aumenta ùëÜ(ùëõ), en la pr√°ctica aparecen costos que la f√≥rmula no modela:

   - Sobresuscripci√≥n: tengo 12 cores. Con 200 o 500 hilos, el SO est√° cambiando de contexto todo el tiempo; eso es tiempo muerto.

   - Contenci√≥n/Sincronizaci√≥n: mi soluci√≥n usa contadores at√≥micos compartidos y una condici√≥n global de paro; con much√≠simos hilos esa contenci√≥n se siente.

   - Carga peque√±a + parada temprana: se detiene al encontrar 5 ocurrencias; muchos hilos ‚Äúllegan tarde‚Äù y no aportan.

   - Cach√©/Memory bandwidth: m√°s hilos peleando por el mismo bus y cach√© no ayuda.

   Por eso, al pasar de 50‚Üí100 hilos ya vi que el tiempo empeora (13‚Üí19 ms). Con 200 o 500, esperar√≠a peor todav√≠a. En resumen: m√°s hilos ‚â† m√°s r√°pido cuando se excede (por mucho) el n√∫mero de cores y la tarea es corta.
   
2. ¬øC√≥mo se comporta la soluci√≥n usando tantos hilos de procesamiento como n√∫cleos comparado con el resultado de usar el doble de √©ste?.

   Con 12 hilos y 24 hilos me dio pr√°cticamente lo mismo (5 ms):

   - Con ~n√∫cleos, la CPU ya est√° llena.

   - Duplicar hilos no agrega capacidad, s√≥lo overhead (planificador, colas, at√≥micos).

   - En problemas con parada temprana, la ganancia adicional es nula o incluso negativa.

   Esto cuadra con Amdahl: si ùëÉ < 1 y el tramo secuencial/overhead empieza a dominar, el speedup se estanca.

3. ¬øDe acuerdo con lo anterior, si para este problema en lugar de 100 hilos en una sola CPU se pudiera usar 1 hilo en cada una de 100 m√°quinas hipot√©ticas, la ley de Amdahls se aplicar√≠a mejor?. Si en lugar de esto se usaran c hilos en 100/c m√°quinas distribuidas (siendo c es el n√∫mero de n√∫cleos de dichas m√°quinas), se mejorar√≠a?. Explique su respuesta.

   - 100 hilos en 1 CPU: sobresuscripci√≥n severa ‚Üí cambios de contexto y contenci√≥n ‚Üí resultados malos (lo vi con 100 hilos: 19 ms).
   - 1 hilo en 100 m√°quinas: cada hilo tendr√≠a su propio core. Eso suena ideal para Amdahl, peeeero aparece nuevo overhead (distribuci√≥n del trabajo, coordinaci√≥n del paro global, latencias de red, agregaci√≥n de resultados, fallos).

      - Si el trabajo fuera grande y ‚Äúembarrassingly parallel‚Äù, s√≠ ver√≠amos beneficios claros.

      - En mi caso (tarea corta, paro en 5 ocurrencias), ese overhead podr√≠a comerse buena parte del beneficio. No espero speedup lineal.

4.  ¬øSi en lugar de esto se usaran c hilos en 100/c m√°quinas distribuidas (siendo c es el n√∫mero de n√∫cleos de dichas m√°quinas), se mejorar√≠a?
    Esa configuraci√≥n mantiene 1 hilo por core a nivel cluster (lo cual evita sobresuscripci√≥n local) y reparte memoria/cach√© entre nodos. Conceptualmente es mejor que 100 hilos comprimidos en una sola CPU. Pero Amdahl sigue mandando: el tramo no paralelizable + la coordinaci√≥n distribuida (red, sincronizaci√≥n del umbral de 5 hallazgos, etc.) limitan el speedup.
    - Si el problema fuera mucho m√°s grande, s√≠ mejorar√≠a respecto a 1 sola m√°quina.
    - Con carga peque√±a como la de este laboratorio, la mejora ser√≠a modesta y no lineal.